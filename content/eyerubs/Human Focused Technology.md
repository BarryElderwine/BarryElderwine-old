---
Journal: "[[241118oms]]"
Project: "[[ðŸ¤“FourSoreEyes]]"
Notes: 
title: Evaluating Technology
date: 2024-11-18
draft: false
categories:
  - Humanity
  - Science
  - Technology
tags:
  - eyerub
---
I'm very curious about the purpose of technology. Specifically my intuitions, based of course on my value driven biases, lead me to believe that all technology should or at least could be evaluated based on its ability to enhance some aspect of humanity and the trade-offs. I think this is supported by the fact that technology, by definition, is always a product of human innovation. This notion however may not hold true with the advent of Artificial Intelligence. 
Some thoughts I want to explore in this regard:

- Would AI driven innovations still be considered human as AI is built based on human experience? 
- If so, is there a point after some number of generations of AI "experience" at which the influence human experience becomes sufficiently diluted such that its innovations and associated technologies are no longer of utility to humanity. And if so, as it seems obvious this could very well be the case, what are the ethical implications for humanity? 



